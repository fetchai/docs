# Multi-agent workflows with Fetch.ai x Langchain

Multi-agent workflows are at the forefront of modern agent development; the idea that individual [agents ↗️](/guides/agents/getting-started/whats-an-agent) can be utilised to create larger more complex services for people has created lots of excitement in the AI space. At Fetch.ai, we're building the agent communication layer which perfectly compliments Langchain libraries.

Agents representing smaller parts of a service, allow for many agents to represent a whole. Agents reduce technical requirements in projects, for example you wouldn't need to write a function to calculate the historical index of a stock price, an agent will already return that data for you.

Before we go any further please read over our introduction guide to [Agents and Langchain](/guides/quickstart-with/langchain/creating-an-agent-with-langchain)

## The system

Three agents make up a simple agent workflow: **RequestAgent**, **PDFQuestionAgent** and **PDFSplitAgent**.

![](src/images/guides/quickstart-with/langchain/multi-agent-workflow-simple.drawio.svg)

A variation of the following `Model` class is passed between each agent:

```
class DocumentUnderstanding(Model):
    pdf_path: str
    question: str

```

The flow is the following:

    - **RequestAgent** provides the `DocumentUnderstanding` object.
    - **PDFQuestionAgent** upon receiving `DocumentUnderstanding` sends a request to the third agent to validate and split the document.
    - **PDFSplitAgent** upon receiving the request from PDFQuestionAgent, returns a list of pages to it.
    - **PDFQuestionAgent** upto receiving the message from PDFSplitAgent processes the pages to answer the question from RequestAgent, then returns that answer to this latter one.

In this example, we are hard coding the agents addresses, meaning we know them. To search for agents dynamically, take a look at the [Almanac ↗️](/concepts/fetch-network/almanac).

## Installation

Run the following:

    ```bash copy
    poetry init
    poetry add uagents requests langchain openai langchain-openai faiss-cpu validators
    ```

Versions used for this example are:

    ```
    [tool.poetry.dependencies]
    python = ">=3.10,<3.12"
    uagents = "0.12.0"
    requests = "^2.31.0"
    langchain = "^0.1.7"
    openai = "^1.12.0"
    langchain-openai = "^0.0.6"
    faiss-cpu = "^1.7.4"
    ```

### Environment setup

    ```
    export OPENAI_API_KEY="YOUR_OPENAI_API_KEY"
    ```

### Agent 1 - RequestAgent: provides a question and a source


This is the our simplest agent; this agent provides a link to a PDF and question to be answered from the document.

```python copy filename="request_agent.py"
from uagents import Agent, Context, Protocol, Model

class DocumentUnderstanding(Model):
    pdf_path: str
    question: str

class DocumentsResponse(Model):
    learnings: str

agent = Agent(
    name="find_in_pdf",
    seed="",
    port=8001,
    endpoint=["http://127.0.0.1:8001/submit"],
)

print("uAgent address: ", agent.address)
summary_protocol = Protocol("Text Summariser")

AGENT_2_FAISS = ""

@agent.on_event("startup")
async def on_startup(ctx: Context):
    await ctx.send(
        AGENT_2_FAISS,
        DocumentUnderstanding(pdf_path="./a.pdf", question="What is the story about?"),
    )

@agent.on_message(model=DocumentsResponse)
async def document_load(ctx: Context, sender: str, msg: DocumentsResponse):
    ctx.logger.info(msg.learnings)


agent.include(summary_protocol, publish_manifest=True)
agent.run()


```

### Agent 2 - PDFQuestionAgent: takes a request and returns a result

The PDFQuestionAgent gets the PDF and the request from the first agent, but is unable to split the PDF. This second agent sends a request to the third agent to split the PDF. Once the pages from the PDF are returned, a FAISS similarity search is ran on the pages by the second agent.

```python copy filename="pdf_question_agent.py"
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_openai import OpenAIEmbeddings
from uagents import Agent, Context, Protocol, Model
from langchain_core.documents import Document
from typing import List
import os
import uuid
import faiss

class PDF_Request(Model):
    pdf_path: str
    session: str

class DocumentUnderstanding(Model):
    pdf_path: str
    question: str

class PagesResponse(Model):
    pages: List
    session: str

class DocumentsResponse(Model):
    learnings: str

faiss_pdf_agent = Agent(
    name="faiss_pdf_agent",
    seed="",
    port=8002,
    endpoint=["http://127.0.0.1:8002/submit"],
)

print("uAgent address: ", faiss_pdf_agent.address)
faiss_protocol = Protocol("FAISS")

RequestAgent = ""
PDF_splitter_address = ""

openai_api_key = os.environ["OPENAI_API_KEY"]
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

@faiss_pdf_agent.on_message(model=DocumentUnderstanding, replies=PDF_Request)
async def document_load(ctx: Context, sender: str, msg: DocumentUnderstanding):
    ctx.logger.info(msg)
    ref = str(uuid.uuid4())
    ctx.storage.set(ref, {"question": msg.question, "sender": sender})
    await ctx.send(
        PDF_splitter_address, PDF_Request(pdf_path=msg.pdf_path, session=ref)
    )

@faiss_pdf_agent.on_message(model=PagesResponse, replies=DocumentsResponse)
async def document_understand(ctx: Context, sender: str, msg: PagesResponse):
    index = faiss.IndexFlatL2(len(embeddings.embed_query("hello")))

    vector_store = FAISS(
        embedding_function=embeddings,
        index=index,
        docstore=InMemoryDocstore(),
        index_to_docstore_id={},
    )

    documents = []
    for page in msg.pages:
        documents.append(
            Document(page_content=page["page_content"], metadata=page["metadata"])
        )

    uuids = [str(uuid.uuid4()) for _ in range(len(documents))]

    vector_store.add_documents(documents=documents, ids=uuids)

    prev = ctx.storage.get(msg.session)

    results = vector_store.similarity_search(
        prev["question"],
        k=2,
    )

    if len(results) > 0:
        await ctx.send(
            prev["sender"], DocumentsResponse(learnings=results[0].page_content)
        )

faiss_pdf_agent.include(faiss_protocol, publish_manifest=True)
faiss_pdf_agent.run()

```

The core difference with agent two compared to other agents you have seen so far is that there are multiple `on_message` decorators. Your agent can have as many any number of message handlers as you want.

**PDFQuestionAgent** also has every request/response model to communicate with **RequestAgent** and **PDFSplitAgent**.

### Agent 3 - PDFSplitAgent: validates the PDF, loads and returns the split

The PDFSplitAgent receives the PDF, and splits the document using the `langchain_community` document loader `PyPDFLoader`. It then returns an array of pages to the second agent.

```python copy filename="pdf_split_agent.py"
from langchain_community.document_loaders import PyPDFLoader
from uagents import Agent, Context, Protocol, Model
from typing import List

class PDF_Request(Model):
    pdf_path: str
    session: str

class PagesResponse(Model):
    pages: List
    session: str

pdf_loader_agent = Agent(
    name="pdf_loader_agent",
    seed="",
    port=8003,
    endpoint=["http://127.0.0.1:8003/submit"],
)

print("uAgent address: ", pdf_loader_agent.address)
pdf_loader_protocol = Protocol("Text Summariser")

@pdf_loader_agent.on_message(model=PDF_Request, replies=PagesResponse)
async def document_load(ctx: Context, sender: str, msg: PDF_Request):
    loader = PyPDFLoader(msg.pdf_path)
    pages = loader.load_and_split()
    await ctx.send(sender, PagesResponse(pages=pages, session=msg.session))

pdf_loader_agent.include(pdf_loader_protocol, publish_manifest=True)
pdf_loader_agent.run()

```

## Run the agents

We need to run the agents backwards so that we can generate their addresses and the update the other agents with their addresses respectively.

Let's run **PDFSplitAgent**, and update **PDFQuestionAgent** with its address:

Run: `poetry run python pdf_split_agent.py`

Update `pdf_question_agent.py` script by filling the `PDF_splitter_address` field with the address of the third agent.

Run `poetry run python pdf_question_agent.py`

Update `request_agent.py` script by filling the `AGENT_2_FAISS` field with the address of the second agent.

Run `poetry run python request_agent.py`

Add the address of the first agent in the dedicated field `RequestAgent` within the script for the second agent, `pdf_question_agent.py`.

### Output

- `request_agent.py:`

    ```
    INFO:     [find_in_pdf]: ['0: this is a tale of two cities which ...']

    ```

- `pdf_question_agent.py:`

    ```
    INFO:     [find_in_pdf]: ['0: this is a tale of two cities which ...']

    ```

- `pdf_split_agent.py:`

    ```
    INFO:     [find_in_pdf]: ['0: this is a tale of two cities which ...']

    ```